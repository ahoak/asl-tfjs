{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "638ab14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /anaconda/envs/py38_default/lib/python3.8/site-packages (4.62.3)\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/anaconda/envs/py38_default/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59498c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "trainingImagesDir = '../public/assets/data/training/asl_alphabet_train'\n",
    "trainingImagesOutputDir = '../public/assets/data/training/asl_alphabet_train_grey'\n",
    "\n",
    "pathlib.Path(trainingImagesOutputDir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "trainingSigns = sorted(os.listdir(trainingImagesDir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41d0e62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing A\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pathlib\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "def process_sign(sign):\n",
    "    IMAGE_FILES = os.listdir(os.path.join(trainingImagesDir, './', sign))\n",
    "    grey_out_dir = os.path.join(trainingImagesOutputDir, './', sign)\n",
    "    pathlib.Path(grey_out_dir).mkdir(parents=True, exist_ok=True)\n",
    "    print(\"Processing \" + sign)\n",
    "    for idx, fileName in enumerate(IMAGE_FILES):\n",
    "        # Read an image, flip it around y-axis for correct handedness output (see\n",
    "        # above).\n",
    "        file = os.path.join(trainingImagesDir, './', sign, fileName)\n",
    "        image = cv2.imread(file)\n",
    "        # Convert the BGR image to RGB before processing.\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        outfile = os.path.join(grey_out_dir, fileName)\n",
    "#         print(outfile)\n",
    "#         print(outfile)\n",
    "        cv2.imwrite(outfile, gray)\n",
    "\n",
    "process_sign(\"A\")\n",
    "# for sign in trainingSigns:\n",
    "#     process_sign(sign)\n",
    "\n",
    "    #     for sign in trainingSigns:\n",
    "    #         process_sign(sign)\n",
    "    #         sign_idx = sign_idx + 1\n",
    "    #         pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04728da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[landmark {\n",
      "  x: 0.551543653011322\n",
      "  y: 0.5552890300750732\n",
      "  z: -8.413272780671832e-07\n",
      "}\n",
      "landmark {\n",
      "  x: 0.46153995394706726\n",
      "  y: 0.5192225575447083\n",
      "  z: -0.013066370971500874\n",
      "}\n",
      "landmark {\n",
      "  x: 0.400984525680542\n",
      "  y: 0.45549237728118896\n",
      "  z: -0.021430889144539833\n",
      "}\n",
      "landmark {\n",
      "  x: 0.3873842656612396\n",
      "  y: 0.39300134778022766\n",
      "  z: -0.03420479968190193\n",
      "}\n",
      "landmark {\n",
      "  x: 0.3905313014984131\n",
      "  y: 0.34014731645584106\n",
      "  z: -0.04334723949432373\n",
      "}\n",
      "landmark {\n",
      "  x: 0.45082783699035645\n",
      "  y: 0.3822767734527588\n",
      "  z: 0.0074765561148524284\n",
      "}\n",
      "landmark {\n",
      "  x: 0.4364841878414154\n",
      "  y: 0.33187755942344666\n",
      "  z: -0.026555348187685013\n",
      "}\n",
      "landmark {\n",
      "  x: 0.4445531666278839\n",
      "  y: 0.3802356719970703\n",
      "  z: -0.049095090478658676\n",
      "}\n",
      "landmark {\n",
      "  x: 0.4541296064853668\n",
      "  y: 0.4280320703983307\n",
      "  z: -0.05729285255074501\n",
      "}\n",
      "landmark {\n",
      "  x: 0.5019063353538513\n",
      "  y: 0.3806082308292389\n",
      "  z: -0.0018953294493258\n",
      "}\n",
      "landmark {\n",
      "  x: 0.4882024824619293\n",
      "  y: 0.3315187692642212\n",
      "  z: -0.037810713052749634\n",
      "}\n",
      "landmark {\n",
      "  x: 0.4962783455848694\n",
      "  y: 0.3972049951553345\n",
      "  z: -0.050835419446229935\n",
      "}\n",
      "landmark {\n",
      "  x: 0.5043812394142151\n",
      "  y: 0.4531628489494324\n",
      "  z: -0.04888897016644478\n",
      "}\n",
      "landmark {\n",
      "  x: 0.5531876087188721\n",
      "  y: 0.3853076994419098\n",
      "  z: -0.016484810039401054\n",
      "}\n",
      "landmark {\n",
      "  x: 0.5357716679573059\n",
      "  y: 0.3387741446495056\n",
      "  z: -0.051087502390146255\n",
      "}\n",
      "landmark {\n",
      "  x: 0.5392382144927979\n",
      "  y: 0.40524566173553467\n",
      "  z: -0.04222505912184715\n",
      "}\n",
      "landmark {\n",
      "  x: 0.5452051162719727\n",
      "  y: 0.4584658443927765\n",
      "  z: -0.02467934414744377\n",
      "}\n",
      "landmark {\n",
      "  x: 0.6057525277137756\n",
      "  y: 0.39756137132644653\n",
      "  z: -0.03242529183626175\n",
      "}\n",
      "landmark {\n",
      "  x: 0.5890512466430664\n",
      "  y: 0.3467114567756653\n",
      "  z: -0.05228975787758827\n",
      "}\n",
      "landmark {\n",
      "  x: 0.5808409452438354\n",
      "  y: 0.3914240300655365\n",
      "  z: -0.037486787885427475\n",
      "}\n",
      "landmark {\n",
      "  x: 0.5798807144165039\n",
      "  y: 0.43320637941360474\n",
      "  z: -0.018974844366312027\n",
      "}\n",
      "]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "tensors=[]\n",
    "count = 0\n",
    "# vidcap = cv2.VideoCapture('output_crf17.mkv')\n",
    "# success,image = vidcap.read()\n",
    "\n",
    "# with mp_hands.Hands(\n",
    "#     static_image_mode=True,\n",
    "#     max_num_hands=2,\n",
    "#     min_detection_confidence=0.5) as hands:\n",
    "#     while success:\n",
    "#         success,image = vidcap.read()\n",
    "        \n",
    "#         if success:\n",
    "#             # Convert the BGR image to RGB before processing.\n",
    "#             results = hands.process(image)\n",
    "\n",
    "#             if not results.multi_hand_landmarks:\n",
    "#                 continue\n",
    "\n",
    "#             for hand_landmarks in results.multi_hand_landmarks:\n",
    "#                 index = 0\n",
    "#                 tensor = np.array([[res.x, res.y, res.z] for res in hand_landmarks.landmark]).flatten()\n",
    "#                 tensors.append(tf.linalg.normalize(tf.constant(tensor)))\n",
    "\n",
    "#             count += 1\n",
    "#     print (count)\n",
    "\n",
    "with mp_hands.Hands(\n",
    "    static_image_mode=True,\n",
    "    max_num_hands=2,\n",
    "    min_detection_confidence=0.5) as hands:\n",
    "    sign = 'A'\n",
    "    IMAGE_FILES = os.listdir(os.path.join(trainingImagesOutputDir, './A'))\n",
    "    for idx, fileName in enumerate(IMAGE_FILES):\n",
    "        # Read an image, flip it around y-axis for correct handedness output (see\n",
    "        # above).\n",
    "        file = os.path.join(trainingImagesDir, './', sign, fileName)\n",
    "        image = cv2.flip(cv2.imread(file), 1)\n",
    "        # Convert the BGR image to RGB before processing.\n",
    "        out = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(out)\n",
    "\n",
    "        if not results.multi_hand_landmarks:\n",
    "            continue\n",
    "        \n",
    "        print (results.multi_hand_landmarks)\n",
    "        break\n",
    "\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            index = 0\n",
    "            tensor = np.array([[res.x, res.y, res.z] for res in hand_landmarks.landmark]).flatten()\n",
    "            tensors.append(tf.linalg.normalize(tf.constant(tensor)))\n",
    "\n",
    "        count += 1\n",
    "    print (count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1d866bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-1.  2.  5.]\n",
      " [ 1.  5.  5.]], shape=(2, 3), dtype=float64)\n",
      "(<tf.Tensor: shape=(2, 3), dtype=float64, numpy=\n",
      "array([[-0.2,  0.4,  1. ],\n",
      "       [ 0.2,  1. ,  1. ]])>, <tf.Tensor: shape=(1, 1), dtype=float64, numpy=array([[5.]])>)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pathlib\n",
    "\n",
    "tensor = tf.constant(np.array([[0.0, 2.0, 5.0], [1.0, 5.0, 5.0]]))\n",
    "print(tensor)\n",
    "print(tf.linalg.normalize(\n",
    "    tensor, ord=np.inf, axis=None, name=None\n",
    "))\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27b9047f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, 12])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.full(2, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7daa25c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
